import streamlit as st
import pandas as pd
import plotly.express as px
import json
import re
from datetime import datetime
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(layout="wide", page_title="–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –æ—Ç–∑—ã–≤–æ–≤ –æ –ì–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫–µ")

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.title("–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –æ—Ç–∑—ã–≤–æ–≤ –æ –ì–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫–µ")

# –°–∞–π–¥–±–∞—Ä –¥–ª—è –≤–∏–¥–∂–µ—Ç–æ–≤
st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

# –í–∏–¥–∂–µ—Ç—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
uploaded_csv = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Å –æ—Ç–∑—ã–≤–∞–º–∏", type=['csv'])
uploaded_json = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ JSON —Å –æ—Ç–∑—ã–≤–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", type=['json'])

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(filename='app_errors.log', level=logging.ERROR,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Å –≤–µ—Å–∞–º–∏
SENTIMENT_LEXICON = {
    'positive': {
        '–æ—Ç–ª–∏—á–Ω': 2, '—Ö–æ—Ä–æ—à': 2, '–ø—Ä–µ–∫—Ä–∞—Å–Ω': 2, '–±—ã—Å—Ç—Ä': 1, '—É–¥–æ–±–Ω': 1, '–ø–æ–Ω—è—Ç–Ω': 1,
        '—Ä–µ–∫–æ–º–µ–Ω–¥': 2, '–¥–æ–≤–æ–ª': 2, '—Å–ø–∞—Å–∏–±': 2, '—Ä–∞–¥': 2, '–ª–µ–≥–∫': 1, '–ø—Ä–∏—è—Ç–Ω': 1,
        '–∫–∞—á–µ—Å—Ç–≤–µ–Ω': 2, '–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª': 2, '–æ–ø–µ—Ä–∞—Ç–∏–≤': 1, '—á–µ—Ç–∫': 1, '–ø—Ä–æ–∑—Ä–∞—á–Ω': 1,
        '–≤—ã–≥–æ–¥–Ω': 2, '–Ω–∞–¥–µ–∂–Ω': 2, '–ª—É—á—à': 2, '—Å—É–ø–µ—Ä': 2, '–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω': 2, '–≤–ø–µ—á–∞—Ç–ª': 2,
        '—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω': 2, '–ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å': 2, '–Ω—Ä–∞–≤–∏—Ç—Å—è': 2, '–≤–æ–≤—Ä–µ–º—è': 1, '—Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω': 1,
        '–≥–ª–∞–¥–∫–æ': 1, '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω': 1, '–±–µ–∑ –ø—Ä–æ–±–ª–µ–º': 2, '–Ω–µ –ø–ª–æ—Ö–æ': 1, '–±–µ–∑ –æ—à–∏–±–æ–∫': 2,
        '–Ω–µ –º–µ–¥–ª–µ–Ω': 1, '–Ω–µ –∑–∞–≤–∏—Å–∞–µ—Ç': 2
    },
    'negative': {
        '–ø–ª–æ—Ö': -2, '—É–∂–∞—Å–Ω': -3, '–º–µ–¥–ª–µ–Ω': -2, '–Ω–µ—É–¥–æ–±–Ω': -2, '—Å–ª–æ–∂–Ω': -2, '–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è': -3,
        '–ø—Ä–æ–±–ª–µ–º': -2, '–æ—à–∏–±–∫': -2, '–≥–ª—é–∫': -2, '–∑–∞–≤–∏—Å–∞': -2, '–Ω–µ —Ä–∞–±–æ—Ç': -3, '–æ—Ç–∫–∞–∑': -2,
        '–æ–±–º–∞–Ω': -3, '–¥–æ—Ä–æ–≥': -2, '–∫–æ–º–∏—Å—Å': -1, '–¥–æ–ª–≥': -2, '–Ω–µ—è—Å–Ω': -1, '–Ω–µ–ø–æ–ª–∞–¥–∫': -2,
        '–Ω–µ–¥–æ–≤–æ–ª': -2, '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω': -3, '–∫–æ—à–º–∞—Ä': -3, '–∑–∞–≤–∏—Å–∞–µ—Ç': -2, '–≤–∏—Å–Ω–µ—Ç': -2, '—Ç—É–ø–∏—Ç': -2,
        '–ª–∞–≥–∞–µ—Ç': -2, '–º–∞–ª–µ–Ω—å–∫': -1
    },
    'neutral': {
        '–Ω–æ—Ä–º–∞–ª—å–Ω': 0, '–æ–±—ã—á–Ω': 0, '—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω': 0, '–ø—Ä–∏–µ–º–ª–µ–º': 0, '–∏–∑–º–µ–Ω–µ–Ω': 0,
        '–æ–∂–∏–¥–∞': 0, '—Å—Ä–µ–¥–Ω': 0, '—Ä–∞–±–æ—Ç': 0, '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω': 0
    }
}

# –£—Å–∏–ª–∏–≤–∞—é—â–∏–µ —Å–ª–æ–≤–∞ –∏ –æ—Ç—Ä–∏—Ü–∞–Ω–∏—è
INTENSIFIERS = {
    '–æ—á–µ–Ω—å': 1.5, '–∫—Ä–∞–π–Ω–µ': 2, '—Å–æ–≤—Å–µ–º': 1.5, '–∞–±—Å–æ–ª—é—Ç–Ω–æ': 2, '–ø–æ–ª–Ω–æ—Å—Ç—å—é': 1.5, '—Å–∏–ª—å–Ω–æ': 1.5,
    '—á—Ä–µ–∑–≤—ã—á–∞–π–Ω–æ': 2, '–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ': 2, '—É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ': 1.5, '–Ω–µ–æ–±—ã—á–Ω–æ': 1.5, '–≤–µ—Å—å–º–∞': 1.5,
    '—Å–ª–∏—à–∫–æ–º': 2, '—á–∞—Å—Ç–æ': 1
}

NEGATION_WORDS = {
    '–Ω–µ', '–Ω–µ—Ç', '–Ω–∏', '–±–µ–∑', '–Ω–µ–ª—å–∑—è', '–Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ', '–Ω–∏–∫–∞–∫', '–Ω–∏—á—É—Ç—å'
}

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ç–µ–º
PRODUCT_CATEGORIES_TOPICS = {
    '–û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ': {
        'keywords': ['–æ–±—Å–ª—É–∂–∏–≤–∞–Ω', '–æ—Ç–¥–µ–ª–µ–Ω–∏', '–∫–ª–∏–µ–Ω—Ç', '–æ—á–µ—Ä–µ–¥', '–ø–µ—Ä—Å–æ–Ω–∞–ª', '–º–µ–Ω–µ–¥–∂–µ—Ä', '–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç', '–ø—Ä–∏–µ–º', '–∫–∞—Å—Å–∞', '–æ–ø–µ—Ä–∞—Ç–æ—Ä', '–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ'],
        'phrases': ['–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –≤ –±–∞–Ω–∫–µ', '–æ—Ç–¥–µ–ª–µ–Ω–∏–µ –±–∞–Ω–∫–∞', '–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä', '–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –≤ –±–∞–Ω–∫–µ', '–æ—á–µ—Ä–µ–¥—å –≤ –æ—Ç–¥–µ–ª–µ–Ω–∏–∏']
    },
    '–ú–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ': {
        'keywords': ['–º–æ–±–∏–ª—å', '–ø—Ä–∏–ª–æ–∂–µ–Ω', '–æ–Ω–ª–∞–π–Ω', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '—Å–º—Å', '–≥–ª—é–∫', '–∑–∞–≤–∏—Å–∞', '–Ω–µ —Ä–∞–±–æ—Ç', '—Ç–æ—Ä–º–æ–∑', '–≤–∏—Å–Ω–µ—Ç', '—Ç—É–ø–∏—Ç', '–ª–∞–≥–∞–µ—Ç'],
        'phrases': ['–º–æ–±–∏–ª—å–Ω—ã–π –±–∞–Ω–∫', '–º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç –±–∞–Ω–∫', '—Å–º—Å –∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–∏—Å–ª–æ']
    },
    '–ö—Ä–µ–¥–∏—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞': {
        'keywords': ['–∫—Ä–µ–¥–∏—Ç–Ω', '–ª–∏–º–∏—Ç', '–æ–¥–æ–±—Ä–µ–Ω', '–ø–æ–≥–∞—à–µ–Ω', '–ø—Ä–æ—Ü–µ–Ω—Ç', '–ø–ª–∞—Ç–µ–∂', '–∑–∞—è–≤–∫'],
        'phrases': ['–∫—Ä–µ–¥–∏—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞', '–æ–¥–æ–±—Ä–µ–Ω–∏–µ –∫—Ä–µ–¥–∏—Ç–∞', '–ø–æ–≥–∞—à–µ–Ω–∏–µ –∫—Ä–µ–¥–∏—Ç–∞', '–∫—Ä–µ–¥–∏—Ç–Ω—ã–π –ª–∏–º–∏—Ç', '–æ—Ñ–æ—Ä–º–∏—Ç—å –∫–∞—Ä—Ç—É']
    }
}

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤
PRODUCT_CATEGORIES_MAIN = {
    '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏': {
        'subcategories': {
            '–í–µ–¥–µ–Ω–∏–µ –≤–∞–ª—é—Ç–Ω—ã—Ö —Å—á–µ—Ç–æ–≤': {'keywords': ['–≤–∞–ª—é—Ç', '—Ä—É–±–ª', '–¥–æ–ª–ª–∞—Ä', '–µ–≤—Ä–æ', '–≤–∞–ª—é—Ç–Ω', '—Å—á–µ—Ç', '–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü', '–æ–±–º–µ–Ω'], 'phrases': ['–≤–∞–ª—é—Ç–Ω—ã–π —Å—á–µ—Ç', '–æ–±–º–µ–Ω –≤–∞–ª—é—Ç—ã', '–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∞–ª—é—Ç—ã']},
            '–î–µ–±–µ—Ç–æ–≤—ã–µ –∫–∞—Ä—Ç—ã': {'keywords': ['–¥–µ–±–µ—Ç', '—Å–Ω—è—Ç–∏–µ', '–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ', '–∫—ç—à–±—ç–∫'], 'phrases': ['–¥–µ–±–µ—Ç–æ–≤–∞—è –∫–∞—Ä—Ç–∞', '–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∫–∞—Ä—Ç—ã', '—Å–Ω—è—Ç–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö']},
            '–ú–æ–±–∏–ª—å–Ω—ã–π –±–∞–Ω–∫': {'keywords': ['–º–æ–±–∏–ª—å', '–ø—Ä–∏–ª–æ–∂–µ–Ω', '–æ–Ω–ª–∞–π–Ω', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '—Å–º—Å'], 'phrases': ['–º–æ–±–∏–ª—å–Ω—ã–π –±–∞–Ω–∫', '–º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç –±–∞–Ω–∫']},
            '–ü–µ—Ä–µ–≤–æ–¥—ã': {'keywords': ['–ø–µ—Ä–µ–≤–æ–¥', '—Å—Ä–µ–¥—Å—Ç–≤', '–¥–µ–Ω—å–≥', '–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ'], 'phrases': ['–ø–µ—Ä–µ–≤–æ–¥ –¥–µ–Ω–µ–≥', '–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥—Å—Ç–≤']},
            '–ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –∫–∞—Ä—Ç—ã': {'keywords': ['–∑–∞—Ä–ø–ª–∞—Ç', '–∑–∞—Ä–ø–ª–∞—Ç–Ω', '–≤—ã–ø–ª–∞—Ç–∞'], 'phrases': ['–∑–∞—Ä–ø–ª–∞—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞', '–≤—ã–ø–ª–∞—Ç–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã']}
        },
        'keywords': ['–ø–µ—Ä–µ–≤–æ–¥', '–∑–∞—Ä–ø–ª–∞—Ç', '–º–æ–±–∏–ª—å', '–±–∞–Ω–∫', '–ø–ª–∞—Ç–µ–∂', '–≤–∞–ª—é—Ç', '—Ä—É–±–ª', '–¥–æ–ª–ª–∞—Ä', '–µ–≤—Ä–æ', '—Å–Ω—è—Ç', '–ø–æ–ª—É—á–µ–Ω', '–±–∞–Ω–∫–æ–º–∞—Ç', '–æ–ø–ª–∞—Ç', '–∫–≤–∏—Ç–∞–Ω—Ü', '–∫–æ–º–∏—Å—Å', '–æ–±—Å–ª—É–∂–≤–∞–Ω', '–æ—Ç–¥–µ–ª–µ–Ω–∏', '–∫–ª–∏–µ–Ω—Ç', '–æ—á–µ—Ä–µ–¥', '–æ–Ω–ª–∞–π–Ω', '–ø—Ä–∏–ª–æ–∂–µ–Ω', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '—Å–º—Å', '—É–≤–µ–¥–æ–º–ª–µ–Ω', '—Å—Ä–µ–¥—Å—Ç–≤', '–¥–µ–Ω—å–≥', '–Ω–∞–ª–∏—á', '–±–µ–∑–Ω–∞–ª', '—Å–±–µ—Ä–∫–Ω–∏–∂–∫', '–≤—ã–ø–∏—Å', '–±–∞–ª–∞–Ω—Å', '–æ—Å—Ç–∞—Ç–æ–∫'],
        'phrases': ['–∑–∞—Ä–ø–ª–∞—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞', '–º–æ–±–∏–ª—å–Ω—ã–π –±–∞–Ω–∫', '–ø–µ—Ä–µ–≤–æ–¥ –¥–µ–Ω–µ–≥', '–æ—Ç–∫—Ä—ã—Ç—å —Å—á–µ—Ç', '–≤–∞–ª—é—Ç–Ω—ã–π —Å—á–µ—Ç', '–±–∞–Ω–∫–æ–≤—Å–∫–∏–π —Å—á–µ—Ç', '—Ä–∞—Å—á–µ—Ç–Ω—ã–π —Å—á–µ—Ç', '—Å–Ω—è—Ç—å –¥–µ–Ω—å–≥–∏', '–ø–æ–ª—É—á–∏—Ç—å –¥–µ–Ω—å–≥–∏', '–æ–ø–ª–∞—Ç–∏—Ç—å —É—Å–ª—É–≥–∏', '–∫–æ–º–∏—Å—Å–∏—è –∑–∞ –ø–µ—Ä–µ–≤–æ–¥', '–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∫–∞—Ä—Ç—ã', '–æ—Ç–¥–µ–ª–µ–Ω–∏–µ –±–∞–Ω–∫–∞', '–æ—á–µ—Ä–µ–¥—å –≤ –±–∞–Ω–∫–µ', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç –±–∞–Ω–∫', '–º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '—Å–º—Å –∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–±–µ–∑–Ω–∞–ª–∏—á–Ω—ã–π —Ä–∞—Å—á–µ—Ç', '–≤—ã–ø–∏—Å–∫–∞ –ø–æ —Å—á–µ—Ç—É', '–æ—Å—Ç–∞—Ç–æ–∫ –Ω–∞ —Å—á–µ—Ç–µ']
    },
    '–°–±–µ—Ä–µ–∂–µ–Ω–∏—è –∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è': {
        'keywords': ['–≤–∫–ª–∞–¥', '—Å–±–µ—Ä–µ–≥–∞—Ç–µ–ª—å–Ω', '–Ω–∞–∫–æ–ø–∏—Ç', '—Å–±–µ—Ä–µ–∂–µ–Ω', '–º–µ—Ç–∞–ª–ª', '—Å—á–µ—Ç', '—Å—Ä–æ—á–Ω', '–ø—Ä–æ—Ü–µ–Ω—Ç', '–Ω–∞–∫–æ–ø', '—Å–±–µ—Ä–µ–≥', '–¥–µ–ø–æ–∑–∏—Ç', '—Å—Ç–∞–≤–∫', '–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç', '–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü', '–ø–æ–ø–æ–ª–Ω–µ–Ω', '—Å–Ω—è—Ç', '–ø—Ä–æ–ª–æ–Ω–≥–∞—Ü', '–ø—Ä–æ—Ü–µ–Ω—Ç—ã', '–Ω–∞—á–∏—Å–ª–µ–Ω', '–∑–∞–±—Ä–∞—Ç', '–ø–æ–ª—É—á–µ–Ω', '–∑–æ–ª–æ—Ç', '—Å–µ—Ä–µ–±—Ä', '–ø–ª–∞—Ç–∏–Ω', '–ø–∞–ª–ª–∞–¥', '—Å–ª–∏—Ç–∫', '—Å–±–µ—Ä–µ–≥–∞—Ç–µ–ª—å–Ω', '—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç', '–Ω–∞–∫–æ–ø–ª–µ–Ω', '–æ—Ç–∫—Ä—ã—Ç', '–∑–∞–∫—Ä—ã—Ç'],
        'phrases': ['—Å—Ä–æ—á–Ω—ã–π –≤–∫–ª–∞–¥', '—Å–±–µ—Ä–µ–≥–∞—Ç–µ–ª—å–Ω—ã–π —Å—á–µ—Ç', '–º–µ—Ç–∞–ª–ª–∏—á–µ—Å–∫–∏–π —Å—á–µ—Ç', '–æ—Ç–∫—Ä—ã—Ç—å –≤–∫–ª–∞–¥', '–Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π —Å—á–µ—Ç', '–æ–±–µ–∑–ª–∏—á–µ–Ω–Ω—ã–π –º–µ—Ç–∞–ª–ª–∏—á–µ—Å–∫–∏–π', '–±–∞–Ω–∫–æ–≤—Å–∫–∏–π –≤–∫–ª–∞–¥', '–¥–µ–ø–æ–∑–∏—Ç–Ω—ã–π —Å—á–µ—Ç', '–ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è —Å—Ç–∞–≤–∫–∞', '–¥–æ—Ö–æ–¥ –ø–æ –≤–∫–ª–∞–¥—É', '–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤', '–ø–æ–ø–æ–ª–Ω–∏—Ç—å –≤–∫–ª–∞–¥', '—Å–Ω—è—Ç—å —Å–æ –≤–∫–ª–∞–¥–∞', '–ø—Ä–æ–ª–æ–Ω–≥–∞—Ü–∏—è –≤–∫–ª–∞–¥–∞', '–Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤', '–∑–∞–±—Ä–∞—Ç—å –≤–∫–ª–∞–¥', '–æ—Ç–∫—Ä—ã—Ç—å –¥–µ–ø–æ–∑–∏—Ç', '–∑–æ–ª–æ—Ç–æ–π —Å–ª–∏—Ç–æ–∫', '—Å–±–µ—Ä–µ–≥–∞—Ç–µ–ª—å–Ω—ã–π —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç', '–Ω–∞–∫–æ–ø–∏—Ç—å –¥–µ–Ω—å–≥–∏']
    },
    '–ö—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–∏–µ': {
        'keywords': ['–∫—Ä–µ–¥–∏—Ç', '–∑–∞–π–º', '–∏–ø–æ—Ç–µ–∫', '–∞–≤—Ç–æ–∫—Ä–µ–¥–∏—Ç', '—Å—Å—É–¥', '–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫', '—Ä–µ—Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏', '–¥–æ–ª–≥', '–ø—Ä–æ—Ü–µ–Ω—Ç', '–ø–ª–∞—Ç–µ–∂', '–ø–æ–≥–∞—à–µ–Ω–∏', '—Å—Ç–∞–≤–∫', '—Å—Ä–æ–∫', '–¥–æ–∫—É–º–µ–Ω—Ç', '–æ—Ñ–æ—Ä–º–ª–µ–Ω', '–æ—Ç–∫–∞–∑', '–æ–¥–æ–±—Ä–µ–Ω', '–ø–µ—Ä–µ–ø–ª–∞—Ç–∞', '–∑–∞–¥–æ–ª–∂–µ–Ω', '–ø—Ä–æ—Å—Ä–æ—á–∫'],
        'phrases': ['–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π –∫—Ä–µ–¥–∏—Ç', '–∏–ø–æ—Ç–µ—á–Ω—ã–π –∫—Ä–µ–¥–∏—Ç', '–∞–≤—Ç–æ–∫—Ä–µ–¥–∏—Ç', '–æ—Ñ–æ—Ä–º–∏—Ç—å –∫—Ä–µ–¥–∏—Ç', '—Ä–µ—Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –∫—Ä–µ–¥–∏—Ç–∞', '–ø—Ä–æ—Ü–µ–Ω—Ç –ø–æ –∫—Ä–µ–¥–∏—Ç—É', '–ø–æ–≥–∞—à–µ–Ω–∏–µ –∫—Ä–µ–¥–∏—Ç–∞', '—Å—Ç–∞–≤–∫–∞ –ø–æ –∫—Ä–µ–¥–∏—Ç—É', '–¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∫—Ä–µ–¥–∏—Ç–∞', '–æ—Ç–∫–∞–∑ –≤ –∫—Ä–µ–¥–∏—Ç–µ', '–ø–µ—Ä–µ–ø–ª–∞—Ç–∞ –ø–æ –∫—Ä–µ–¥–∏—Ç—É']
    },
    '–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏': {
        'keywords': ['–∏–Ω–≤–µ—Å—Ç–∏—Ü', '–±—Ä–æ–∫–µ—Ä', '–∞–∫—Ü–∏', '–æ–±–ª–∏–≥–∞—Ü', '—Ñ–æ–Ω–¥—ã', '–ø–æ—Ä—Ç—Ñ–µ–ª—å', '–¥–æ—Ö–æ–¥', '—Ä–∏—Å–∫', '–¥–∏–≤–∏–¥–µ–Ω–¥', '—Ç–æ—Ä–≥–æ–≤', '–±–∏—Ä–∂', '—É–ø—Ä–∞–≤–ª–µ–Ω', '–ø—Ä–∏–±—ã–ª—å', '—É–±—ã—Ç–æ–∫', '–∏–Ω–¥–µ–∫—Å'],
        'phrases': ['–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å', '–ø–æ–∫—É–ø–∫–∞ –∞–∫—Ü–∏–π', '–æ–±–ª–∏–≥–∞—Ü–∏–∏ –±–∞–Ω–∫–∞', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–æ–Ω–¥—ã', '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏', '–¥–∏–≤–∏–¥–µ–Ω–¥—ã –ø–æ –∞–∫—Ü–∏—è–º', '—Ç–æ—Ä–≥–æ–≤–ª—è –Ω–∞ –±–∏—Ä–∂–µ', '–∏–Ω–¥–µ–∫—Å–Ω—ã–π —Ñ–æ–Ω–¥']
    },
    '–°—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ –∏ –∑–∞—â–∏—Ç–∞': {
        'keywords': ['—Å—Ç—Ä–∞—Ö–æ–≤–∫', '–ø–æ–ª–∏—Å', '–≤—ã–ø–ª–∞—Ç', '—É—â–µ—Ä–±', '—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω', '—Ä–∏—Å–∫', '–æ—Ñ–æ—Ä–º–ª–µ–Ω', '–ø—Ä–µ—Ç–µ–Ω–∑–∏', '–≤–æ–∑–º–µ—â–µ–Ω', '–¥–æ–∫—É–º–µ–Ω—Ç', '—Å—Ä–æ–∫', '—É—Å–ª—É–≥', '—É—â–µ—Ä–±'],
        'phrases': ['—Å—Ç—Ä–∞—Ö–æ–≤–æ–π –ø–æ–ª–∏—Å', '–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ö–æ–≤–∫–∏', '–≤—ã–ø–ª–∞—Ç–∞ –ø–æ —Å—Ç—Ä–∞—Ö–æ–≤–∫–µ', '–≤–æ–∑–º–µ—â–µ–Ω–∏–µ —É—â–µ—Ä–±–∞', '—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ –∂–∏–∑–Ω–∏', '–ø—Ä–µ—Ç–µ–Ω–∑–∏—è –ø–æ —Å—Ç—Ä–∞—Ö–æ–≤–∫–µ']
    },
    '–ü—Ä–µ–º–∏–∞–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏': {
        'keywords': ['–ø—Ä–µ–º–∏—É–º', '–ø—Ä–∏–≤–∏–ª–µ–≥–∏', '—ç–ª–∏—Ç', 'VIP', '–æ–±—Å–ª—É–∂–∏–≤–∞–Ω', '—É—Å–ª—É–≥', '–¥–æ—Å—Ç—É–ø', '—Å–∫–∏–¥–∫', '–±–æ–Ω—É—Å', '—Å—Ç–∞—Ç—É—Å', '–∫–∞—Ä—Ç–∞', '–ø—Ä–µ–¥–ª–æ–∂–µ–Ω'],
        'phrases': ['–ø—Ä–µ–º–∏–∞–ª—å–Ω–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ', '–ø—Ä–∏–≤–∏–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç', 'VIP-–∫–∞—Ä—Ç–∞', '—ç–ª–∏—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å', '–±–æ–Ω—É—Å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞']
    }
}

# –§—É–Ω–∫—Ü–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
def classify_sentiment(text):
    text = text.lower()
    sentiment_score = 0
    words = re.findall(r'\w+', text)
    
    for i, word in enumerate(words):
        base_score = 0
        for sentiment, keywords in SENTIMENT_LEXICON.items():
            for key, score in keywords.items():
                if key in word:
                    base_score = score
                    break
            if base_score != 0:
                break
        
        if base_score != 0:
            if i > 0 and words[i-1] in INTENSIFIERS:
                base_score *= INTENSIFIERS[words[i-1]]
            if i > 0 and words[i-1] in NEGATION_WORDS:
                base_score = -base_score
            
            sentiment_score += base_score
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Å –±–æ–ª–µ–µ —Ç–æ–Ω–∫–æ–π –≥—Ä–∞–¥–∞—Ü–∏–µ–π
    if sentiment_score >= 2:
        return '–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ'
    elif sentiment_score <= -2:
        return '–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ'
    elif -1 < sentiment_score < 1:
        return '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ'
    return '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

def classify_topics(text):
    text = text.lower()
    categories = set()
    words = set(re.findall(r'\w+', text))
    
    for category, data in PRODUCT_CATEGORIES_TOPICS.items():
        keywords = set(data['keywords'])
        phrases = set(data['phrases'])
        if any(word in keywords for word in words) or any(phrase in text for phrase in phrases):
            categories.add(category)
    
    return list(categories) if categories else ['–î—Ä—É–≥–æ–µ']

def classify_product_category(text, topics):
    text = text.lower()
    categories = set()
    words = set(re.findall(r'\w+', text))
    
    for category, data in PRODUCT_CATEGORIES_MAIN.items():
        keywords = set(data['keywords'])
        phrases = set(data['phrases'])
        matched = False
        if any(word in keywords for word in words) or any(phrase in text for phrase in phrases):
            matched = True
        if matched and 'subcategories' in data:
            for subcategory, subdata in data['subcategories'].items():
                sub_keywords = set(subdata['keywords'])
                sub_phrases = set(subdata['phrases'])
                sub_matched = False
                if any(word in sub_keywords for word in words) or any(phrase in text for phrase in sub_phrases):
                    sub_matched = True
                if sub_matched:
                    categories.add(f"{category} - {subcategory}")
        else:
            categories.add(category)

    if len(categories) > 1 and '–î—Ä—É–≥–æ–µ' in categories:
        categories.remove('–î—Ä—É–≥–æ–µ')
    return list(categories) if categories else ['–î—Ä—É–≥–æ–µ']

def process_review(review):
    text = review.get('text', '')
    id = review.get('id', 0)
    
    parts = re.split(r'\b–Ω–æ\b', text, flags=re.IGNORECASE)
    parts = [p.strip() for p in parts if p.strip()]
    
    topics = []
    sentiments = []
    
    if parts:
        for part in parts:
            part_topics = classify_topics(part)
            sentiment = classify_sentiment(part)
            for topic in part_topics:
                if topic not in topics:
                    topics.append(topic)
                    sentiments.append(sentiment)
    else:
        topics = classify_topics(text)
        sentiment = classify_sentiment(text)
        sentiments = [sentiment] * len(topics)
    
    if len(topics) > 1 and '–î—Ä—É–≥–æ–µ' in topics:
        idx = topics.index('–î—Ä—É–≥–æ–µ')
        topics.pop(idx)
        sentiments.pop(idx)
    
    current_date = datetime.now().strftime('%d.%m.%Y')
    rating_map = {'–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ': 1, '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ': 3, '–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ': 5}
    source = 'gold'
    author = review.get('author', '–ö–ª–∏–µ–Ω—Ç –±–∞–Ω–∫–∞')
    title = ' '.join(re.findall(r'\w+', text)[:5]) if text else '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞'
    product_categories = classify_product_category(text, topics)
    
    try:
        df = pd.read_csv('gazprombank_reviews_classified.csv', sep=';', encoding='utf-8-sig')
    except FileNotFoundError:
        df = pd.DataFrame(columns=['text', 'topics', 'sentiments', 'date', 'rating', 'source', 'id', 'author', 'title', 'product_category'])
    except Exception as e:
        logging.error(f"Error reading CSV file: {str(e)}")
        return {'id': id, 'topics': topics, 'sentiments': sentiments, 'error': f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"}
    
    topics_str = ', '.join(topics)
    sentiments_str = ', '.join(sentiments)
    product_category_str = ', '.join(product_categories)
    
    # –†–∞—Å—á—ë—Ç —Ä–µ–π—Ç–∏–Ω–≥–∞ —Å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    avg_rating = sum(rating_map.get(s, 3) for s in sentiments) / len(sentiments) if sentiments else 3
    avg_rating = round(avg_rating * 2) / 2  # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ 0.5 (1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5)

    try:
        new_review = pd.DataFrame({
            'text': [text],
            'topics': [topics_str],
            'sentiments': [sentiments_str],
            'date': [current_date],
            'rating': [avg_rating],
            'source': [source],
            'id': [id],
            'author': [author],
            'title': [title],
            'product_category': [product_category_str]
        })
        df = pd.concat([df, new_review], ignore_index=True)
        df.to_csv('gazprombank_reviews_classified.csv', index=False, sep=';', encoding='utf-8-sig')
    except Exception as e:
        logging.error(f"Error writing to CSV file: {str(e)}")
        return {'id': id, 'topics': topics, 'sentiments': sentiments, 'error': f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª: {str(e)}"}
    
    return {'id': id, 'topics': topics, 'sentiments': sentiments, 'product_category': product_categories}

@st.cache_data
def load_data(uploaded_file, file_type):
    if uploaded_file is not None:
        if file_type == 'csv':
            df = pd.read_csv(uploaded_file, sep=';', encoding='utf-8-sig', on_bad_lines='skip')
        else:  # json
            data = json.load(uploaded_file)
            if 'data' in data and isinstance(data['data'], list):
                predictions = []
                for review in data['data']:
                    result = process_review(review)
                    if 'error' not in result:
                        predictions.append(result)
                # –°–æ–∑–¥–∞—ë–º DataFrame –±–µ–∑ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–æ–∫–∏
                rows = []
                for pred, orig in zip(predictions, data['data']):
                    row = {
                        'id': pred['id'],
                        'text': orig.get('text', ''),
                        'topics': ', '.join(pred['topics']),
                        'sentiments': ', '.join(pred['sentiments']),
                        'product_category': ', '.join(pred['product_category']),
                        'date': orig.get('date', datetime.now().strftime('%d.%m.%Y')),
                        'rating': orig.get('rating', 3),
                        'author': orig.get('author', '–ö–ª–∏–µ–Ω—Ç –±–∞–Ω–∫–∞'),
                        'source': orig.get('source', 'gold'),
                        'title': ' '.join(re.findall(r'\w+', orig.get('text', ''))[:5]) if orig.get('text', '') else '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞'
                    }
                    rows.append(row)
                df = pd.DataFrame(rows)
            else:
                st.error("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON. –û–∂–∏–¥–∞–µ—Ç—Å—è {'data': [{'id': 1, 'text': '...'}]}")
                return pd.DataFrame()

        if not df.empty:
            required_cols = ['text']
            if not all(col in df.columns for col in required_cols):
                missing_cols = [col for col in required_cols if col not in df.columns]
                st.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
                return pd.DataFrame()

            if 'product_category' not in df.columns:
                df['product_category'] = df['text'].apply(lambda x: ', '.join(classify_product_category(x, classify_topics(x))))
            if 'sentiments' not in df.columns:
                df['sentiments'] = df['text'].apply(classify_sentiment)
            if 'topics' not in df.columns:
                df['topics'] = df['text'].apply(lambda x: ', '.join(classify_topics(x)))

            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y', errors='coerce')
            if 'id' not in df.columns:
                df['id'] = df.index + 1

            st.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫. –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã: {sorted(df['product_category'].unique())}")
            if 'date' in df.columns:
                st.info(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {df['date'].min().strftime('%d.%m.%Y')} - {df['date'].max().strftime('%d.%m.%Y')}")

            return df
    return pd.DataFrame()

if uploaded_csv or uploaded_json:
    df = load_data(uploaded_csv if uploaded_csv else uploaded_json, 'csv' if uploaded_csv else 'json')
else:
    df = pd.DataFrame()
    st.sidebar.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ JSON —Å –æ—Ç–∑—ã–≤–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

if not df.empty:
    st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã")
    min_date_default = datetime(2024, 1, 1).date()
    max_date_default = datetime(2025, 5, 31).date()
    min_date = min_date_default if 'date' not in df.columns or df['date'].isna().all() else max(min_date_default, df['date'].min().date())
    max_date = max_date_default if 'date' not in df.columns or df['date'].isna().all() else min(max_date_default, df['date'].max().date())
    start_date = st.sidebar.date_input("–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞", min_date, min_value=min_date_default, max_value=max_date_default)
    end_date = st.sidebar.date_input("–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞", max_date if max_date <= max_date_default else max_date_default, 
                                    min_value=min_date_default, max_value=max_date_default)

    source_options = ['–í—Å–µ'] + sorted(df['source'].dropna().unique().tolist()) if 'source' in df.columns else ['–í—Å–µ']
    source_filter = st.sidebar.multiselect("–ò—Å—Ç–æ—á–Ω–∏–∫", options=source_options, default=['–í—Å–µ'])

    sentiment_options = ['–í—Å–µ'] + ['–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ', '–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ', '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ']
    sentiment_filter = st.sidebar.multiselect("–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å", options=sentiment_options, default=['–í—Å–µ'])

    main_product_options = ['–í—Å–µ'] + sorted([cat for cat in df['product_category'].unique() if ' - ' not in str(cat)])
    product_filter = st.sidebar.multiselect("–ö–∞—Ç–µ–≥–æ—Ä–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞", options=main_product_options, default=['–í—Å–µ'])

    subcategories_filter = []
    if '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏' in product_filter and len(product_filter) == 1:
        subcategories = sorted([cat for cat in df['product_category'].unique() if cat.startswith('–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏ - ')])
        subcategories_filter = st.sidebar.multiselect("–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞", options=subcategories, default=subcategories)

    if '–í—Å–µ' in product_filter and len(product_filter) > 1:
        product_filter = ['–í—Å–µ']
        subcategories_filter = []
        st.rerun()

    rating_filter = st.sidebar.slider("–†–µ–π—Ç–∏–Ω–≥", min_value=1, max_value=5, value=(1, 5), step=0.5) if 'rating' in df.columns else (1, 5)
    keyword_filter = st.sidebar.text_input("–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –≤ —Ç–µ–∫—Å—Ç–µ", "")

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–æ–∫ –∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç
    mask = pd.Series(True, index=df.index)
    if 'date' in df.columns:
        mask &= (df['date'].dt.date >= datetime(2024, 1, 1)) & (df['date'].dt.date <= datetime(2025, 5, 31))
        mask &= (df['date'].dt.date >= start_date) & (df['date'].dt.date <= end_date)
    if 'rating' in df.columns:
        mask &= df['rating'].between(*rating_filter)
    if 'source' in df.columns and source_filter and '–í—Å–µ' not in source_filter:
        mask &= df['source'].isin(source_filter)
    if 'sentiments' in df.columns and sentiment_filter and '–í—Å–µ' not in sentiment_filter:
        mask &= df['sentiments'].str.contains('|'.join(sentiment_filter), case=False, na=False)
    if product_filter and '–í—Å–µ' not in product_filter:
        mask &= df['product_category'].str.contains('|'.join(product_filter + subcategories_filter), case=False, na=False)
    if 'text' in df.columns and keyword_filter:
        mask &= df['text'].str.contains(keyword_filter, case=False, na=False, regex=True)

    filtered_df = df[mask].copy()

    st.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_df)} —Å—Ç—Ä–æ–∫. –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –≤ —Ñ–∏–ª—å—Ç—Ä–µ: {sorted(filtered_df['product_category'].unique())}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    st.header("üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    group_cols = ['id', 'text'] if 'id' in filtered_df.columns else ['text']
    total_reviews = len(filtered_df.groupby(group_cols).size()) if not filtered_df.empty else 0
    st.write(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤: {total_reviews}")

    # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    st.subheader("üòä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
    if 'sentiments' in filtered_df and not filtered_df['sentiments'].isna().all():
        def count_sentiments(s):
            return pd.Series(s.split(', ')).value_counts()
        sentiment_counts = filtered_df['sentiments'].apply(count_sentiments).sum().sort_index()
        fig_sentiment = px.pie(names=sentiment_counts.index, values=sentiment_counts.values, title="–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –æ—Ç–∑—ã–≤–æ–≤",
                              color=sentiment_counts.index,
                              color_discrete_map={'–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ': '#90EE90', '–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ': '#FF6347', '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ': '#D3D3D3'},
                              height=600)
        st.plotly_chart(fig_sentiment, use_container_width=True)
    else:
        st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.")

    # –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º –ø–æ –º–µ—Å—è—Ü–∞–º
    st.subheader("üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º –ø–æ –º–µ—Å—è—Ü–∞–º")
    if 'date' in filtered_df and 'product_category' in filtered_df and not filtered_df.empty:
        filtered_df['month'] = filtered_df['date'].dt.to_period('M').astype(str)
        product_monthly = filtered_df.groupby(['month', 'product_category']).size().reset_index(name='count')
        if not product_monthly.empty:
            if '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏' in product_filter and len(product_filter) == 1:
                product_monthly = product_monthly[product_monthly['product_category'].isin(['–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏'] + subcategories_filter)]
            else:
                product_monthly = product_monthly[~product_monthly['product_category'].str.contains(' - ', na=False)]
            if not product_monthly.empty:
                fig_product_trend = px.line(product_monthly, x='month', y='count', color='product_category', title="–û—Ç–∑—ã–≤—ã –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º –ø–æ –º–µ—Å—è—Ü–∞–º",
                                           height=600)
                st.plotly_chart(fig_product_trend, use_container_width=True)
            else:
                st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏.")
        else:
            st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏.")
    else:
        st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏.")

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤
    st.subheader("üìã –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
    if 'product_category' in filtered_df and not filtered_df['product_category'].isna().all():
        product_counts = filtered_df['product_category'].str.split(', ').explode().value_counts()
        if not product_counts.empty:
            if not product_filter or ('–í—Å–µ' in product_filter and len(product_filter) == 1):
                product_counts_filtered = product_counts[~product_counts.index.str.contains(' - ', na=False)]
            elif '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏' in product_filter and len(product_filter) == 1:
                product_counts_filtered = product_counts[product_counts.index.isin(['–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏'] + subcategories_filter)]
            else:
                product_counts_filtered = product_counts[~product_counts.index.str.contains(' - ', na=False)]

            if not product_counts_filtered.empty:
                fig_product = px.bar(x=product_counts_filtered.index, y=product_counts_filtered.values, title="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤",
                                    color=product_counts_filtered.index,
                                    color_discrete_map={
                                        '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏': '#1f77b4',
                                        '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏ - –í–µ–¥–µ–Ω–∏–µ –≤–∞–ª—é—Ç–Ω—ã—Ö —Å—á–µ—Ç–æ–≤': '#1f77b4',
                                        '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏ - –î–µ–±–µ—Ç–æ–≤—ã–µ –∫–∞—Ä—Ç—ã': '#1f77b4',
                                        '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏ - –ú–æ–±–∏–ª—å–Ω—ã–π –±–∞–Ω–∫': '#1f77b4',
                                        '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏ - –ü–µ—Ä–µ–≤–æ–¥—ã': '#1f77b4',
                                        '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–ª–∞—Ç–µ–∂–∏ - –ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –∫–∞—Ä—Ç—ã': '#1f77b4',
                                        '–°–±–µ—Ä–µ–∂–µ–Ω–∏—è –∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è': '#ff7f0e',
                                        '–ö—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–∏–µ': '#2ca02c',
                                        '–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏': '#d62728',
                                        '–°—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ –∏ –∑–∞—â–∏—Ç–∞': '#9467bd',
                                        '–ü—Ä–µ–º–∏–∞–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏': '#8c564b',
                                        '–î—Ä—É–≥–æ–µ': '#bcbd22'
                                    },
                                    height=600)
                st.plotly_chart(fig_product, use_container_width=True)
            else:
                st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π.")
        else:
            st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π.")

    # –¢–∞–±–ª–∏—Ü–∞ –æ—Ç–∑—ã–≤–æ–≤
    st.subheader("üìù –ü–æ–¥—Ä–æ–±–Ω—ã–µ –æ—Ç–∑—ã–≤—ã")
    if not filtered_df.empty:
        group_cols_table = ['id', 'date', 'author', 'title', 'text', 'rating', 'sentiments', 'source', 'topics', 'product_category'] if all(col in filtered_df.columns for col in ['id', 'date', 'author', 'title', 'text', 'rating', 'sentiments', 'source', 'topics', 'product_category']) else ['date', 'author', 'title', 'text', 'rating', 'sentiments', 'source', 'topics', 'product_category']
        display_df = filtered_df[group_cols_table]
        st.dataframe(display_df, width=1500, height=800)
    else:
        st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã.")
else:
    st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ JSON —Å –æ—Ç–∑—ã–≤–∞–º–∏.")
