import streamlit as st
import pandas as pd
import plotly.express as px
import json
import re
from datetime import datetime
import logging

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹
st.set_page_config(layout="wide", page_title="ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð² Ð¾ Ð“Ð°Ð·Ð¿Ñ€Ð¾Ð¼Ð±Ð°Ð½ÐºÐµ")

# Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
st.title("ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð² Ð¾ Ð“Ð°Ð·Ð¿Ñ€Ð¾Ð¼Ð±Ð°Ð½ÐºÐµ")

# Ð¡Ð°Ð¹Ð´Ð±Ð°Ñ€ Ð´Ð»Ñ Ð²Ð¸Ð´Ð¶ÐµÑ‚Ð¾Ð²
st.sidebar.header("ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…")

# Ð’Ð¸Ð´Ð¶ÐµÑ‚Ñ‹ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ñ„Ð°Ð¹Ð»Ð¾Ð²
uploaded_csv = st.sidebar.file_uploader("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ CSV Ñ Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ð¼Ð¸", type=['csv'])
uploaded_json = st.sidebar.file_uploader("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ JSON Ñ Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ð¼Ð¸ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°", type=['json'])

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logging.basicConfig(filename='app_errors.log', level=logging.ERROR,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ð´Ð»Ñ Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ñ Ð²ÐµÑÐ°Ð¼Ð¸
SENTIMENT_LEXICON = {
    'positive': {
        'Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½': 2, 'Ñ…Ð¾Ñ€Ð¾Ñˆ': 2, 'Ð¿Ñ€ÐµÐºÑ€Ð°ÑÐ½': 2, 'Ð±Ñ‹ÑÑ‚Ñ€': 1, 'ÑƒÐ´Ð¾Ð±Ð½': 1, 'Ð¿Ð¾Ð½ÑÑ‚Ð½': 1,
        'Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´': 2, 'Ð´Ð¾Ð²Ð¾Ð»': 2, 'ÑÐ¿Ð°ÑÐ¸Ð±': 2, 'Ñ€Ð°Ð´': 2, 'Ð»ÐµÐ³Ðº': 1, 'Ð¿Ñ€Ð¸ÑÑ‚Ð½': 1,
        'ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½': 2, 'Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»': 2, 'Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²': 1, 'Ñ‡ÐµÑ‚Ðº': 1, 'Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½': 1,
        'Ð²Ñ‹Ð³Ð¾Ð´Ð½': 2, 'Ð½Ð°Ð´ÐµÐ¶Ð½': 2, 'Ð»ÑƒÑ‡Ñˆ': 2, 'ÑÑƒÐ¿ÐµÑ€': 2, 'Ð·Ð°Ð¼ÐµÑ‡Ð°Ñ‚ÐµÐ»ÑŒÐ½': 2, 'Ð²Ð¿ÐµÑ‡Ð°Ñ‚Ð»': 2,
        'ÑƒÐ´Ð¾Ð²Ð»ÐµÑ‚Ð²Ð¾Ñ€ÐµÐ½': 2, 'Ð¿Ð¾Ð½Ñ€Ð°Ð²Ð¸Ð»Ð¾ÑÑŒ': 2, 'Ð½Ñ€Ð°Ð²Ð¸Ñ‚ÑÑ': 2, 'Ð²Ð¾Ð²Ñ€ÐµÐ¼Ñ': 1, 'ÑÐ²Ð¾ÐµÐ²Ñ€ÐµÐ¼ÐµÐ½': 1,
        'Ð³Ð»Ð°Ð´ÐºÐ¾': 1, 'ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½': 1, 'Ð±ÐµÐ· Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼': 2, 'Ð½Ðµ Ð¿Ð»Ð¾Ñ…Ð¾': 1, 'Ð±ÐµÐ· Ð¾ÑˆÐ¸Ð±Ð¾Ðº': 2,
        'Ð½Ðµ Ð¼ÐµÐ´Ð»ÐµÐ½': 1, 'Ð½Ðµ Ð·Ð°Ð²Ð¸ÑÐ°ÐµÑ‚': 2
    },
    'negative': {
        'Ð¿Ð»Ð¾Ñ…': -2, 'ÑƒÐ¶Ð°ÑÐ½': -3, 'Ð¼ÐµÐ´Ð»ÐµÐ½': -2, 'Ð½ÐµÑƒÐ´Ð¾Ð±Ð½': -2, 'ÑÐ»Ð¾Ð¶Ð½': -2, 'Ð½Ðµ Ð½Ñ€Ð°Ð²Ð¸Ñ‚ÑÑ': -3,
        'Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼': -2, 'Ð¾ÑˆÐ¸Ð±Ðº': -2, 'Ð³Ð»ÑŽÐº': -2, 'Ð·Ð°Ð²Ð¸ÑÐ°': -2, 'Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚': -3, 'Ð¾Ñ‚ÐºÐ°Ð·': -2,
        'Ð¾Ð±Ð¼Ð°Ð½': -3, 'Ð´Ð¾Ñ€Ð¾Ð³': -2, 'ÐºÐ¾Ð¼Ð¸ÑÑ': -1, 'Ð´Ð¾Ð»Ð³': -2, 'Ð½ÐµÑÑÐ½': -1, 'Ð½ÐµÐ¿Ð¾Ð»Ð°Ð´Ðº': -2,
        'Ð½ÐµÐ´Ð¾Ð²Ð¾Ð»': -2, 'Ñ€Ð°Ð·Ð¾Ñ‡Ð°Ñ€Ð¾Ð²Ð°Ð½': -3, 'ÐºÐ¾ÑˆÐ¼Ð°Ñ€': -3, 'Ð·Ð°Ð²Ð¸ÑÐ°ÐµÑ‚': -2, 'Ð²Ð¸ÑÐ½ÐµÑ‚': -2, 'Ñ‚ÑƒÐ¿Ð¸Ñ‚': -2,
        'Ð»Ð°Ð³Ð°ÐµÑ‚': -2, 'Ð¼Ð°Ð»ÐµÐ½ÑŒÐº': -1
    },
    'neutral': {
        'Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½': 0, 'Ð¾Ð±Ñ‹Ñ‡Ð½': 0, 'ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½': 0, 'Ð¿Ñ€Ð¸ÐµÐ¼Ð»ÐµÐ¼': 0, 'Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½': 0,
        'Ð¾Ð¶Ð¸Ð´Ð°': 0, 'ÑÑ€ÐµÐ´Ð½': 0, 'Ñ€Ð°Ð±Ð¾Ñ‚': 0, 'Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½': 0
    }
}

# Ð£ÑÐ¸Ð»Ð¸Ð²Ð°ÑŽÑ‰Ð¸Ðµ ÑÐ»Ð¾Ð²Ð° Ð¸ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ð½Ð¸Ñ
INTENSIFIERS = {
    'Ð¾Ñ‡ÐµÐ½ÑŒ': 1.5, 'ÐºÑ€Ð°Ð¹Ð½Ðµ': 2, 'ÑÐ¾Ð²ÑÐµÐ¼': 1.5, 'Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¾': 2, 'Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ': 1.5, 'ÑÐ¸Ð»ÑŒÐ½Ð¾': 1.5,
    'Ñ‡Ñ€ÐµÐ·Ð²Ñ‹Ñ‡Ð°Ð¹Ð½Ð¾': 2, 'Ð½ÐµÐ²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾': 2, 'ÑƒÐ´Ð¸Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾': 1.5, 'Ð½ÐµÐ¾Ð±Ñ‹Ñ‡Ð½Ð¾': 1.5, 'Ð²ÐµÑÑŒÐ¼Ð°': 1.5,
    'ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼': 2, 'Ñ‡Ð°ÑÑ‚Ð¾': 1
}

NEGATION_WORDS = {
    'Ð½Ðµ', 'Ð½ÐµÑ‚', 'Ð½Ð¸', 'Ð±ÐµÐ·', 'Ð½ÐµÐ»ÑŒÐ·Ñ', 'Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾', 'Ð½Ð¸ÐºÐ°Ðº', 'Ð½Ð¸Ñ‡ÑƒÑ‚ÑŒ'
}

# Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ð´Ð»Ñ Ñ‚ÐµÐ¼
PRODUCT_CATEGORIES_TOPICS = {
    'ÐžÐ±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ': {
        'keywords': ['Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½', 'Ð¾Ñ‚Ð´ÐµÐ»ÐµÐ½Ð¸', 'ÐºÐ»Ð¸ÐµÐ½Ñ‚', 'Ð¾Ñ‡ÐµÑ€ÐµÐ´', 'Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»', 'Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€', 'ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ð½Ñ‚', 'Ð¿Ñ€Ð¸ÐµÐ¼', 'ÐºÐ°ÑÑÐ°', 'Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€', 'Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ'],
        'phrases': ['Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð² Ð±Ð°Ð½ÐºÐµ', 'Ð¾Ñ‚Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð±Ð°Ð½ÐºÐ°', 'Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€', 'ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ñ Ð² Ð±Ð°Ð½ÐºÐµ', 'Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÐµÐ½Ð¸Ð¸']
    },
    'ÐœÐ¾Ð±Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ': {
        'keywords': ['Ð¼Ð¾Ð±Ð¸Ð»ÑŒ', 'Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½', 'Ð¾Ð½Ð»Ð°Ð¹Ð½', 'Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚', 'ÑÐ¼Ñ', 'Ð³Ð»ÑŽÐº', 'Ð·Ð°Ð²Ð¸ÑÐ°', 'Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚', 'Ñ‚Ð¾Ñ€Ð¼Ð¾Ð·', 'Ð²Ð¸ÑÐ½ÐµÑ‚', 'Ñ‚ÑƒÐ¿Ð¸Ñ‚', 'Ð»Ð°Ð³Ð°ÐµÑ‚'],
        'phrases': ['Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð°Ð½Ðº', 'Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ', 'Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð±Ð°Ð½Ðº', 'ÑÐ¼Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ', 'Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð·Ð°Ð²Ð¸ÑÐ»Ð¾']
    },
    'ÐšÑ€ÐµÐ´Ð¸Ñ‚Ð½Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð°': {
        'keywords': ['ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð½', 'Ð»Ð¸Ð¼Ð¸Ñ‚', 'Ð¾Ð´Ð¾Ð±Ñ€ÐµÐ½', 'Ð¿Ð¾Ð³Ð°ÑˆÐµÐ½', 'Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚', 'Ð¿Ð»Ð°Ñ‚ÐµÐ¶', 'Ð·Ð°ÑÐ²Ðº'],
        'phrases': ['ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð½Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð°', 'Ð¾Ð´Ð¾Ð±Ñ€ÐµÐ½Ð¸Ðµ ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð°', 'Ð¿Ð¾Ð³Ð°ÑˆÐµÐ½Ð¸Ðµ ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð°', 'ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð½Ñ‹Ð¹ Ð»Ð¸Ð¼Ð¸Ñ‚', 'Ð¾Ñ„Ð¾Ñ€Ð¼Ð¸Ñ‚ÑŒ ÐºÐ°Ñ€Ñ‚Ñƒ']
    }
}

# Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð²
PRODUCT_CATEGORIES_MAIN = {
    'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸': {
        'subcategories': {
            'Ð’ÐµÐ´ÐµÐ½Ð¸Ðµ Ð²Ð°Ð»ÑŽÑ‚Ð½Ñ‹Ñ… ÑÑ‡ÐµÑ‚Ð¾Ð²': {'keywords': ['Ð²Ð°Ð»ÑŽÑ‚', 'Ñ€ÑƒÐ±Ð»', 'Ð´Ð¾Ð»Ð»Ð°Ñ€', 'ÐµÐ²Ñ€Ð¾', 'Ð²Ð°Ð»ÑŽÑ‚Ð½', 'ÑÑ‡ÐµÑ‚', 'ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†', 'Ð¾Ð±Ð¼ÐµÐ½'], 'phrases': ['Ð²Ð°Ð»ÑŽÑ‚Ð½Ñ‹Ð¹ ÑÑ‡ÐµÑ‚', 'Ð¾Ð±Ð¼ÐµÐ½ Ð²Ð°Ð»ÑŽÑ‚Ñ‹', 'ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð²Ð°Ð»ÑŽÑ‚Ñ‹']},
            'Ð”ÐµÐ±ÐµÑ‚Ð¾Ð²Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹': {'keywords': ['Ð´ÐµÐ±ÐµÑ‚', 'ÑÐ½ÑÑ‚Ð¸Ðµ', 'Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ', 'ÐºÑÑˆÐ±ÑÐº'], 'phrases': ['Ð´ÐµÐ±ÐµÑ‚Ð¾Ð²Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð°', 'Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹', 'ÑÐ½ÑÑ‚Ð¸Ðµ Ð½Ð°Ð»Ð¸Ñ‡Ð½Ñ‹Ñ…']},
            'ÐœÐ¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð°Ð½Ðº': {'keywords': ['Ð¼Ð¾Ð±Ð¸Ð»ÑŒ', 'Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½', 'Ð¾Ð½Ð»Ð°Ð¹Ð½', 'Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚', 'ÑÐ¼Ñ'], 'phrases': ['Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð°Ð½Ðº', 'Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ', 'Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð±Ð°Ð½Ðº']},
            'ÐŸÐµÑ€ÐµÐ²Ð¾Ð´Ñ‹': {'keywords': ['Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´', 'ÑÑ€ÐµÐ´ÑÑ‚Ð²', 'Ð´ÐµÐ½ÑŒÐ³', 'Ð¿ÐµÑ€ÐµÑ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ'], 'phrases': ['Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ Ð´ÐµÐ½ÐµÐ³', 'Ð¿ÐµÑ€ÐµÑ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÑ€ÐµÐ´ÑÑ‚Ð²']},
            'Ð—Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹': {'keywords': ['Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚', 'Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð½', 'Ð²Ñ‹Ð¿Ð»Ð°Ñ‚Ð°'], 'phrases': ['Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð½Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð°', 'Ð²Ñ‹Ð¿Ð»Ð°Ñ‚Ð° Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ñ‹']}
        },
        'keywords': ['Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´', 'Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚', 'Ð¼Ð¾Ð±Ð¸Ð»ÑŒ', 'Ð±Ð°Ð½Ðº', 'Ð¿Ð»Ð°Ñ‚ÐµÐ¶', 'Ð²Ð°Ð»ÑŽÑ‚', 'Ñ€ÑƒÐ±Ð»', 'Ð´Ð¾Ð»Ð»Ð°Ñ€', 'ÐµÐ²Ñ€Ð¾', 'ÑÐ½ÑÑ‚', 'Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½', 'Ð±Ð°Ð½ÐºÐ¾Ð¼Ð°Ñ‚', 'Ð¾Ð¿Ð»Ð°Ñ‚', 'ÐºÐ²Ð¸Ñ‚Ð°Ð½Ñ†', 'ÐºÐ¾Ð¼Ð¸ÑÑ', 'Ð¾Ð±ÑÐ»ÑƒÐ¶Ð²Ð°Ð½', 'Ð¾Ñ‚Ð´ÐµÐ»ÐµÐ½Ð¸', 'ÐºÐ»Ð¸ÐµÐ½Ñ‚', 'Ð¾Ñ‡ÐµÑ€ÐµÐ´', 'Ð¾Ð½Ð»Ð°Ð¹Ð½', 'Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½', 'Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚', 'ÑÐ¼Ñ', 'ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½', 'ÑÑ€ÐµÐ´ÑÑ‚Ð²', 'Ð´ÐµÐ½ÑŒÐ³', 'Ð½Ð°Ð»Ð¸Ñ‡', 'Ð±ÐµÐ·Ð½Ð°Ð»', 'ÑÐ±ÐµÑ€ÐºÐ½Ð¸Ð¶Ðº', 'Ð²Ñ‹Ð¿Ð¸Ñ', 'Ð±Ð°Ð»Ð°Ð½Ñ', 'Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ðº'],
        'phrases': ['Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð½Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð°', 'Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð°Ð½Ðº', 'Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ Ð´ÐµÐ½ÐµÐ³', 'Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚ÑŒ ÑÑ‡ÐµÑ‚', 'Ð²Ð°Ð»ÑŽÑ‚Ð½Ñ‹Ð¹ ÑÑ‡ÐµÑ‚', 'Ð±Ð°Ð½ÐºÐ¾Ð²ÑÐºÐ¸Ð¹ ÑÑ‡ÐµÑ‚', 'Ñ€Ð°ÑÑ‡ÐµÑ‚Ð½Ñ‹Ð¹ ÑÑ‡ÐµÑ‚', 'ÑÐ½ÑÑ‚ÑŒ Ð´ÐµÐ½ÑŒÐ³Ð¸', 'Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´ÐµÐ½ÑŒÐ³Ð¸', 'Ð¾Ð¿Ð»Ð°Ñ‚Ð¸Ñ‚ÑŒ ÑƒÑÐ»ÑƒÐ³Ð¸', 'ÐºÐ¾Ð¼Ð¸ÑÑÐ¸Ñ Ð·Ð° Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´', 'Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹', 'Ð¾Ñ‚Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð±Ð°Ð½ÐºÐ°', 'Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ Ð² Ð±Ð°Ð½ÐºÐµ', 'Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð±Ð°Ð½Ðº', 'Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ', 'ÑÐ¼Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ', 'Ð±ÐµÐ·Ð½Ð°Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ Ñ€Ð°ÑÑ‡ÐµÑ‚', 'Ð²Ñ‹Ð¿Ð¸ÑÐºÐ° Ð¿Ð¾ ÑÑ‡ÐµÑ‚Ñƒ', 'Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ðº Ð½Ð° ÑÑ‡ÐµÑ‚Ðµ']
    },
    'Ð¡Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸Ñ Ð¸ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸Ñ': {
        'keywords': ['Ð²ÐºÐ»Ð°Ð´', 'ÑÐ±ÐµÑ€ÐµÐ³Ð°Ñ‚ÐµÐ»ÑŒÐ½', 'Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚', 'ÑÐ±ÐµÑ€ÐµÐ¶ÐµÐ½', 'Ð¼ÐµÑ‚Ð°Ð»Ð»', 'ÑÑ‡ÐµÑ‚', 'ÑÑ€Ð¾Ñ‡Ð½', 'Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚', 'Ð½Ð°ÐºÐ¾Ð¿', 'ÑÐ±ÐµÑ€ÐµÐ³', 'Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚', 'ÑÑ‚Ð°Ð²Ðº', 'Ð´Ð¾Ñ…Ð¾Ð´Ð½Ð¾ÑÑ‚', 'ÐºÐ°Ð¿Ð¸Ñ‚Ð°Ð»Ð¸Ð·Ð°Ñ†', 'Ð¿Ð¾Ð¿Ð¾Ð»Ð½ÐµÐ½', 'ÑÐ½ÑÑ‚', 'Ð¿Ñ€Ð¾Ð»Ð¾Ð½Ð³Ð°Ñ†', 'Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ñ‹', 'Ð½Ð°Ñ‡Ð¸ÑÐ»ÐµÐ½', 'Ð·Ð°Ð±Ñ€Ð°Ñ‚', 'Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½', 'Ð·Ð¾Ð»Ð¾Ñ‚', 'ÑÐµÑ€ÐµÐ±Ñ€', 'Ð¿Ð»Ð°Ñ‚Ð¸Ð½', 'Ð¿Ð°Ð»Ð»Ð°Ð´', 'ÑÐ»Ð¸Ñ‚Ðº', 'ÑÐ±ÐµÑ€ÐµÐ³Ð°Ñ‚ÐµÐ»ÑŒÐ½', 'ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚', 'Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½', 'Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚', 'Ð·Ð°ÐºÑ€Ñ‹Ñ‚'],
        'phrases': ['ÑÑ€Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð²ÐºÐ»Ð°Ð´', 'ÑÐ±ÐµÑ€ÐµÐ³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÑÑ‡ÐµÑ‚', 'Ð¼ÐµÑ‚Ð°Ð»Ð»Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÑÑ‡ÐµÑ‚', 'Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚ÑŒ Ð²ÐºÐ»Ð°Ð´', 'Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÑÑ‡ÐµÑ‚', 'Ð¾Ð±ÐµÐ·Ð»Ð¸Ñ‡ÐµÐ½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð°Ð»Ð»Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹', 'Ð±Ð°Ð½ÐºÐ¾Ð²ÑÐºÐ¸Ð¹ Ð²ÐºÐ»Ð°Ð´', 'Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð½Ñ‹Ð¹ ÑÑ‡ÐµÑ‚', 'Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð½Ð°Ñ ÑÑ‚Ð°Ð²ÐºÐ°', 'Ð´Ð¾Ñ…Ð¾Ð´ Ð¿Ð¾ Ð²ÐºÐ»Ð°Ð´Ñƒ', 'ÐºÐ°Ð¿Ð¸Ñ‚Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð¾Ð²', 'Ð¿Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð²ÐºÐ»Ð°Ð´', 'ÑÐ½ÑÑ‚ÑŒ ÑÐ¾ Ð²ÐºÐ»Ð°Ð´Ð°', 'Ð¿Ñ€Ð¾Ð»Ð¾Ð½Ð³Ð°Ñ†Ð¸Ñ Ð²ÐºÐ»Ð°Ð´Ð°', 'Ð½Ð°Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð¾Ð²', 'Ð·Ð°Ð±Ñ€Ð°Ñ‚ÑŒ Ð²ÐºÐ»Ð°Ð´', 'Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚ÑŒ Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚', 'Ð·Ð¾Ð»Ð¾Ñ‚Ð¾Ð¹ ÑÐ»Ð¸Ñ‚Ð¾Ðº', 'ÑÐ±ÐµÑ€ÐµÐ³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚', 'Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÑŒ Ð´ÐµÐ½ÑŒÐ³Ð¸']
    },
    'ÐšÑ€ÐµÐ´Ð¸Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ðµ': {
        'keywords': ['ÐºÑ€ÐµÐ´Ð¸Ñ‚', 'Ð·Ð°Ð¹Ð¼', 'Ð¸Ð¿Ð¾Ñ‚ÐµÐº', 'Ð°Ð²Ñ‚Ð¾ÐºÑ€ÐµÐ´Ð¸Ñ‚', 'ÑÑÑƒÐ´', 'Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¸Ñ‚ÐµÐ»ÑŒÑÐº', 'Ñ€ÐµÑ„Ð¸Ð½Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸', 'Ð´Ð¾Ð»Ð³', 'Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚', 'Ð¿Ð»Ð°Ñ‚ÐµÐ¶', 'Ð¿Ð¾Ð³Ð°ÑˆÐµÐ½Ð¸', 'ÑÑ‚Ð°Ð²Ðº', 'ÑÑ€Ð¾Ðº', 'Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚', 'Ð¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½', 'Ð¾Ñ‚ÐºÐ°Ð·', 'Ð¾Ð´Ð¾Ð±Ñ€ÐµÐ½', 'Ð¿ÐµÑ€ÐµÐ¿Ð»Ð°Ñ‚Ð°', 'Ð·Ð°Ð´Ð¾Ð»Ð¶ÐµÐ½', 'Ð¿Ñ€Ð¾ÑÑ€Ð¾Ñ‡Ðº'],
        'phrases': ['Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¸Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ð¹ ÐºÑ€ÐµÐ´Ð¸Ñ‚', 'Ð¸Ð¿Ð¾Ñ‚ÐµÑ‡Ð½Ñ‹Ð¹ ÐºÑ€ÐµÐ´Ð¸Ñ‚', 'Ð°Ð²Ñ‚Ð¾ÐºÑ€ÐµÐ´Ð¸Ñ‚', 'Ð¾Ñ„Ð¾Ñ€Ð¼Ð¸Ñ‚ÑŒ ÐºÑ€ÐµÐ´Ð¸Ñ‚', 'Ñ€ÐµÑ„Ð¸Ð½Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð°', 'Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚ Ð¿Ð¾ ÐºÑ€ÐµÐ´Ð¸Ñ‚Ñƒ', 'Ð¿Ð¾Ð³Ð°ÑˆÐµÐ½Ð¸Ðµ ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð°', 'ÑÑ‚Ð°Ð²ÐºÐ° Ð¿Ð¾ ÐºÑ€ÐµÐ´Ð¸Ñ‚Ñƒ', 'Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð°', 'Ð¾Ñ‚ÐºÐ°Ð· Ð² ÐºÑ€ÐµÐ´Ð¸Ñ‚Ðµ', 'Ð¿ÐµÑ€ÐµÐ¿Ð»Ð°Ñ‚Ð° Ð¿Ð¾ ÐºÑ€ÐµÐ´Ð¸Ñ‚Ñƒ']
    },
    'Ð˜Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸Ð¸': {
        'keywords': ['Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†', 'Ð±Ñ€Ð¾ÐºÐµÑ€', 'Ð°ÐºÑ†Ð¸', 'Ð¾Ð±Ð»Ð¸Ð³Ð°Ñ†', 'Ñ„Ð¾Ð½Ð´Ñ‹', 'Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒ', 'Ð´Ð¾Ñ…Ð¾Ð´', 'Ñ€Ð¸ÑÐº', 'Ð´Ð¸Ð²Ð¸Ð´ÐµÐ½Ð´', 'Ñ‚Ð¾Ñ€Ð³Ð¾Ð²', 'Ð±Ð¸Ñ€Ð¶', 'ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½', 'Ð¿Ñ€Ð¸Ð±Ñ‹Ð»ÑŒ', 'ÑƒÐ±Ñ‹Ñ‚Ð¾Ðº', 'Ð¸Ð½Ð´ÐµÐºÑ'],
        'phrases': ['Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒ', 'Ð¿Ð¾ÐºÑƒÐ¿ÐºÐ° Ð°ÐºÑ†Ð¸Ð¹', 'Ð¾Ð±Ð»Ð¸Ð³Ð°Ñ†Ð¸Ð¸ Ð±Ð°Ð½ÐºÐ°', 'Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ñ„Ð¾Ð½Ð´Ñ‹', 'ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð°ÐºÑ‚Ð¸Ð²Ð°Ð¼Ð¸', 'Ð´Ð¸Ð²Ð¸Ð´ÐµÐ½Ð´Ñ‹ Ð¿Ð¾ Ð°ÐºÑ†Ð¸ÑÐ¼', 'Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ð»Ñ Ð½Ð° Ð±Ð¸Ñ€Ð¶Ðµ', 'Ð¸Ð½Ð´ÐµÐºÑÐ½Ñ‹Ð¹ Ñ„Ð¾Ð½Ð´']
    },
    'Ð¡Ñ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸ Ð·Ð°Ñ‰Ð¸Ñ‚Ð°': {
        'keywords': ['ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ðº', 'Ð¿Ð¾Ð»Ð¸Ñ', 'Ð²Ñ‹Ð¿Ð»Ð°Ñ‚', 'ÑƒÑ‰ÐµÑ€Ð±', 'ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½', 'Ñ€Ð¸ÑÐº', 'Ð¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½', 'Ð¿Ñ€ÐµÑ‚ÐµÐ½Ð·Ð¸', 'Ð²Ð¾Ð·Ð¼ÐµÑ‰ÐµÐ½', 'Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚', 'ÑÑ€Ð¾Ðº', 'ÑƒÑÐ»ÑƒÐ³', 'ÑƒÑ‰ÐµÑ€Ð±'],
        'phrases': ['ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð»Ð¸Ñ', 'Ð¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²ÐºÐ¸', 'Ð²Ñ‹Ð¿Ð»Ð°Ñ‚Ð° Ð¿Ð¾ ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²ÐºÐµ', 'Ð²Ð¾Ð·Ð¼ÐµÑ‰ÐµÐ½Ð¸Ðµ ÑƒÑ‰ÐµÑ€Ð±Ð°', 'ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¶Ð¸Ð·Ð½Ð¸', 'Ð¿Ñ€ÐµÑ‚ÐµÐ½Ð·Ð¸Ñ Ð¿Ð¾ ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²ÐºÐµ']
    },
    'ÐŸÑ€ÐµÐ¼Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑƒÑÐ»ÑƒÐ³Ð¸': {
        'keywords': ['Ð¿Ñ€ÐµÐ¼Ð¸ÑƒÐ¼', 'Ð¿Ñ€Ð¸Ð²Ð¸Ð»ÐµÐ³Ð¸', 'ÑÐ»Ð¸Ñ‚', 'VIP', 'Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½', 'ÑƒÑÐ»ÑƒÐ³', 'Ð´Ð¾ÑÑ‚ÑƒÐ¿', 'ÑÐºÐ¸Ð´Ðº', 'Ð±Ð¾Ð½ÑƒÑ', 'ÑÑ‚Ð°Ñ‚ÑƒÑ', 'ÐºÐ°Ñ€Ñ‚Ð°', 'Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½'],
        'phrases': ['Ð¿Ñ€ÐµÐ¼Ð¸Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑÐ»ÑƒÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ', 'Ð¿Ñ€Ð¸Ð²Ð¸Ð»ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚', 'VIP-ÐºÐ°Ñ€Ñ‚Ð°', 'ÑÐ»Ð¸Ñ‚Ð½Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ', 'Ð±Ð¾Ð½ÑƒÑÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°']
    }
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
def classify_sentiment(text):
    text = text.lower()
    sentiment_score = 0
    words = re.findall(r'\w+', text)
    
    for i, word in enumerate(words):
        base_score = 0
        for sentiment, keywords in SENTIMENT_LEXICON.items():
            for key, score in keywords.items():
                if key in word:
                    base_score = score
                    break
            if base_score != 0:
                break
        
        if base_score != 0:
            if i > 0 and words[i-1] in INTENSIFIERS:
                base_score *= INTENSIFIERS[words[i-1]]
            if i > 0 and words[i-1] in NEGATION_WORDS:
                base_score = -base_score
            
            sentiment_score += base_score
    
    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ñ Ð±Ð¾Ð»ÐµÐµ Ñ‚Ð¾Ð½ÐºÐ¾Ð¹ Ð³Ñ€Ð°Ð´Ð°Ñ†Ð¸ÐµÐ¹
    if sentiment_score >= 2:
        return 'Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾'
    elif sentiment_score <= -2:
        return 'Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾'
    elif -1 < sentiment_score < 1:
        return 'Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾'
    return 'Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾'  # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ

def classify_topics(text):
    text = text.lower()
    categories = set()
    words = set(re.findall(r'\w+', text))
    
    for category, data in PRODUCT_CATEGORIES_TOPICS.items():
        keywords = set(data['keywords'])
        phrases = set(data['phrases'])
        if any(word in keywords for word in words) or any(phrase in text for phrase in phrases):
            categories.add(category)
    
    return list(categories) if categories else ['Ð”Ñ€ÑƒÐ³Ð¾Ðµ']

def classify_product_category(text, topics):
    text = text.lower()
    categories = set()
    words = set(re.findall(r'\w+', text))
    
    for category, data in PRODUCT_CATEGORIES_MAIN.items():
        keywords = set(data['keywords'])
        phrases = set(data['phrases'])
        matched = False
        if any(word in keywords for word in words) or any(phrase in text for phrase in phrases):
            matched = True
        if matched and 'subcategories' in data:
            for subcategory, subdata in data['subcategories'].items():
                sub_keywords = set(subdata['keywords'])
                sub_phrases = set(subdata['phrases'])
                sub_matched = False
                if any(word in sub_keywords for word in words) or any(phrase in text for phrase in sub_phrases):
                    sub_matched = True
                if sub_matched:
                    categories.add(f"{category} - {subcategory}")
        else:
            categories.add(category)

    if len(categories) > 1 and 'Ð”Ñ€ÑƒÐ³Ð¾Ðµ' in categories:
        categories.remove('Ð”Ñ€ÑƒÐ³Ð¾Ðµ')
    return list(categories) if categories else ['Ð”Ñ€ÑƒÐ³Ð¾Ðµ']

def process_review(review):
    text = review.get('text', '')
    id = review.get('id', 0)
    
    parts = re.split(r'\bÐ½Ð¾\b', text, flags=re.IGNORECASE)
    parts = [p.strip() for p in parts if p.strip()]
    
    topics = []
    sentiments = []
    
    if parts:
        for part in parts:
            part_topics = classify_topics(part)
            sentiment = classify_sentiment(part)
            for topic in part_topics:
                if topic not in topics:
                    topics.append(topic)
                    sentiments.append(sentiment)
    else:
        topics = classify_topics(text)
        sentiment = classify_sentiment(text)
        sentiments = [sentiment] * len(topics)
    
    if len(topics) > 1 and 'Ð”Ñ€ÑƒÐ³Ð¾Ðµ' in topics:
        idx = topics.index('Ð”Ñ€ÑƒÐ³Ð¾Ðµ')
        topics.pop(idx)
        sentiments.pop(idx)
    
    current_date = datetime.now().strftime('%d.%m.%Y')
    rating_map = {'Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾': 1, 'Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾': 3, 'Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾': 5}
    source = 'gold'
    author = review.get('author', 'ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð±Ð°Ð½ÐºÐ°')
    title = ' '.join(re.findall(r'\w+', text)[:5]) if text else 'Ð‘ÐµÐ· Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°'
    product_categories = classify_product_category(text, topics)
    
    try:
        df = pd.read_csv('gazprombank_reviews_classified.csv', sep=';', encoding='utf-8-sig')
    except FileNotFoundError:
        df = pd.DataFrame(columns=['text', 'topics', 'sentiments', 'date', 'rating', 'source', 'id', 'author', 'title', 'product_category'])
    except Exception as e:
        logging.error(f"Error reading CSV file: {str(e)}")
        return {'id': id, 'topics': topics, 'sentiments': sentiments, 'error': f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ‡Ñ‚ÐµÐ½Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð°: {str(e)}"}
    
    topics_str = ', '.join(topics)
    sentiments_str = ', '.join(sentiments)
    product_category_str = ', '.join(product_categories)
    
    # Ð Ð°ÑÑ‡Ñ‘Ñ‚ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð° Ñ Ð¿Ñ€Ð¾Ð¼ÐµÐ¶ÑƒÑ‚Ð¾Ñ‡Ð½Ñ‹Ð¼Ð¸ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÑÐ¼Ð¸
    avg_rating = sum(rating_map.get(s, 3) for s in sentiments) / len(sentiments) if sentiments else 3
    avg_rating = round(avg_rating * 2) / 2  # ÐžÐºÑ€ÑƒÐ³Ð»ÐµÐ½Ð¸Ðµ Ð´Ð¾ Ð±Ð»Ð¸Ð¶Ð°Ð¹ÑˆÐµÐ³Ð¾ 0.5 (1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5)

    try:
        new_review = pd.DataFrame({
            'text': [text],
            'topics': [topics_str],
            'sentiments': [sentiments_str],
            'date': [current_date],
            'rating': [avg_rating],
            'source': [source],
            'id': [id],
            'author': [author],
            'title': [title],
            'product_category': [product_category_str]
        })
        df = pd.concat([df, new_review], ignore_index=True)
        df.to_csv('gazprombank_reviews_classified.csv', index=False, sep=';', encoding='utf-8-sig')
    except Exception as e:
        logging.error(f"Error writing to CSV file: {str(e)}")
        return {'id': id, 'topics': topics, 'sentiments': sentiments, 'error': f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² Ñ„Ð°Ð¹Ð»: {str(e)}"}
    
    return {'id': id, 'topics': topics, 'sentiments': sentiments, 'product_category': product_categories}

@st.cache_data
def load_data(uploaded_file, file_type):
    if uploaded_file is not None:
        if file_type == 'csv':
            df = pd.read_csv(uploaded_file, sep=';', encoding='utf-8-sig', on_bad_lines='skip')
        else:  # json
            data = json.load(uploaded_file)
            if 'data' in data and isinstance(data['data'], list):
                predictions = []
                for review in data['data']:
                    result = process_review(review)
                    if 'error' not in result:
                        predictions.append(result)
                # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ DataFrame Ð±ÐµÐ· Ñ€Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ñ Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÐ¸
                rows = []
                for pred, orig in zip(predictions, data['data']):
                    row = {
                        'id': pred['id'],
                        'text': orig.get('text', ''),
                        'topics': ', '.join(pred['topics']),
                        'sentiments': ', '.join(pred['sentiments']),
                        'product_category': ', '.join(pred['product_category']),
                        'date': orig.get('date', datetime.now().strftime('%d.%m.%Y')),
                        'rating': orig.get('rating', 3),
                        'author': orig.get('author', 'ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð±Ð°Ð½ÐºÐ°'),
                        'source': orig.get('source', 'gold'),
                        'title': ' '.join(re.findall(r'\w+', orig.get('text', ''))[:5]) if orig.get('text', '') else 'Ð‘ÐµÐ· Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°'
                    }
                    rows.append(row)
                df = pd.DataFrame(rows)
            else:
                st.error("ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ JSON. ÐžÐ¶Ð¸Ð´Ð°ÐµÑ‚ÑÑ {'data': [{'id': 1, 'text': '...'}]}")
                return pd.DataFrame()

        if not df.empty:
            required_cols = ['text']
            if not all(col in df.columns for col in required_cols):
                missing_cols = [col for col in required_cols if col not in df.columns]
                st.error(f"ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸: {missing_cols}. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ.")
                return pd.DataFrame()

            if 'product_category' not in df.columns:
                df['product_category'] = df['text'].apply(lambda x: ', '.join(classify_product_category(x, classify_topics(x))))
            if 'sentiments' not in df.columns:
                df['sentiments'] = df['text'].apply(classify_sentiment)
            if 'topics' not in df.columns:
                df['topics'] = df['text'].apply(lambda x: ', '.join(classify_topics(x)))

            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y', errors='coerce')
            if 'id' not in df.columns:
                df['id'] = df.index + 1

            st.info(f"Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(df)} ÑÑ‚Ñ€Ð¾Ðº. Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñ‹: {sorted(df['product_category'].unique())}")
            if 'date' in df.columns:
                st.info(f"Ð”Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½ Ð´Ð°Ñ‚: {df['date'].min().strftime('%d.%m.%Y')} - {df['date'].max().strftime('%d.%m.%Y')}")

            return df
    return pd.DataFrame()

if uploaded_csv or uploaded_json:
    df = load_data(uploaded_csv if uploaded_csv else uploaded_json, 'csv' if uploaded_csv else 'json')
else:
    df = pd.DataFrame()
    st.sidebar.warning("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ CSV Ð¸Ð»Ð¸ JSON Ñ Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ð¼Ð¸ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°")

if not df.empty:
    st.sidebar.header("Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹")
    min_date_default = datetime(2024, 1, 1).date()
    max_date_default = datetime(2025, 5, 31).date()
    min_date = df['date'].min().date() if 'date' in df and pd.notna(df['date'].min()) and df['date'].min().date() >= min_date_default else min_date_default
    max_date = df['date'].max().date() if 'date' in df and pd.notna(df['date'].max()) and df['date'].max().date() <= max_date_default else max_date_default
    start_date = st.sidebar.date_input("ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð°Ñ‚Ð°", min_date, min_value=min_date_default, max_value=max_date_default)
    end_date = st.sidebar.date_input("ÐšÐ¾Ð½ÐµÑ‡Ð½Ð°Ñ Ð´Ð°Ñ‚Ð°", max_date if max_date <= max_date_default else max_date_default, 
                                    min_value=min_date_default, max_value=max_date_default)

    source_options = ['Ð’ÑÐµ'] + sorted(df['source'].dropna().unique().tolist()) if 'source' in df.columns else ['Ð’ÑÐµ']
    source_filter = st.sidebar.multiselect("Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº", options=source_options, default=['Ð’ÑÐµ'])

    sentiment_options = ['Ð’ÑÐµ'] + ['Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾', 'Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾', 'Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾']
    sentiment_filter = st.sidebar.multiselect("Ð¢Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ", options=sentiment_options, default=['Ð’ÑÐµ'])

    main_product_options = ['Ð’ÑÐµ'] + sorted([cat for cat in df['product_category'].unique() if ' - ' not in str(cat)])
    product_filter = st.sidebar.multiselect("ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð°", options=main_product_options, default=['Ð’ÑÐµ'])

    subcategories_filter = []
    if 'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸' in product_filter and len(product_filter) == 1:
        subcategories = sorted([cat for cat in df['product_category'].unique() if cat.startswith('ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸ - ')])
        subcategories_filter = st.sidebar.multiselect("ÐŸÐ¾Ð´ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð°", options=subcategories, default=subcategories)

    if 'Ð’ÑÐµ' in product_filter and len(product_filter) > 1:
        product_filter = ['Ð’ÑÐµ']
        subcategories_filter = []
        st.rerun()

    rating_filter = st.sidebar.slider("Ð ÐµÐ¹Ñ‚Ð¸Ð½Ð³", min_value=1, max_value=5, value=(1, 5), step=0.5) if 'rating' in df.columns else (1, 5)
    keyword_filter = st.sidebar.text_input("ÐšÐ»ÑŽÑ‡ÐµÐ²Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ", "")

    # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¾Ð¹ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ñ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð¸ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð° Ð´Ð°Ñ‚
    mask = pd.Series(True, index=df.index)
    if 'date' in df.columns:
        mask &= (df['date'].dt.date >= datetime(2024, 1, 1)) & (df['date'].dt.date <= datetime(2025, 5, 31))
        mask &= (df['date'].dt.date >= start_date) & (df['date'].dt.date <= end_date)
    if 'rating' in df.columns:
        mask &= df['rating'].between(*rating_filter)
    if 'source' in df.columns and source_filter and 'Ð’ÑÐµ' not in source_filter:
        mask &= df['source'].isin(source_filter)
    if 'sentiments' in df.columns and sentiment_filter and 'Ð’ÑÐµ' not in sentiment_filter:
        mask &= df['sentiments'].str.contains('|'.join(sentiment_filter), case=False, na=False)
    if product_filter and 'Ð’ÑÐµ' not in product_filter:
        mask &= df['product_category'].str.contains('|'.join(product_filter + subcategories_filter), case=False, na=False)
    if 'text' in df.columns and keyword_filter:
        mask &= df['text'].str.contains(keyword_filter, case=False, na=False, regex=True)

    filtered_df = df[mask].copy()

    st.info(f"ÐŸÐ¾ÑÐ»Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸: {len(filtered_df)} ÑÑ‚Ñ€Ð¾Ðº. Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñ‹ Ð² Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ðµ: {sorted(filtered_df['product_category'].unique())}")

    # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
    st.header("ðŸ“Š ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°")
    group_cols = ['id', 'text'] if 'id' in filtered_df.columns else ['text']
    total_reviews = len(filtered_df.groupby(group_cols).size()) if not filtered_df.empty else 0
    st.write(f"Ð’ÑÐµÐ³Ð¾ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²: {total_reviews}")

    # Ð“Ñ€Ð°Ñ„Ð¸Ðº Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    st.subheader("ðŸ˜Š Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸")
    if 'sentiments' in filtered_df and not filtered_df['sentiments'].isna().all():
        def count_sentiments(s):
            return pd.Series(s.split(', ')).value_counts()
        sentiment_counts = filtered_df['sentiments'].apply(count_sentiments).sum().sort_index()
        fig_sentiment = px.pie(names=sentiment_counts.index, values=sentiment_counts.values, title="Ð¢Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²",
                              color=sentiment_counts.index,
                              color_discrete_map={'Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾': '#90EE90', 'Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾': '#FF6347', 'Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾': '#D3D3D3'},
                              height=600)
        st.plotly_chart(fig_sentiment, use_container_width=True)
    else:
        st.write("ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸.")

    # Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° Ð¿Ð¾ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð°Ð¼ Ð¿Ð¾ Ð¼ÐµÑÑÑ†Ð°Ð¼
    st.subheader("ðŸ“ˆ Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° Ð¿Ð¾ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð°Ð¼ Ð¿Ð¾ Ð¼ÐµÑÑÑ†Ð°Ð¼")
    if 'date' in filtered_df and 'product_category' in filtered_df and not filtered_df.empty:
        filtered_df['month'] = filtered_df['date'].dt.to_period('M').astype(str)
        product_monthly = filtered_df.groupby(['month', 'product_category']).size().reset_index(name='count')
        if not product_monthly.empty:
            if 'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸' in product_filter and len(product_filter) == 1:
                product_monthly = product_monthly[product_monthly['product_category'].isin(['ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸'] + subcategories_filter)]
            else:
                product_monthly = product_monthly[~product_monthly['product_category'].str.contains(' - ', na=False)]
            if not product_monthly.empty:
                fig_product_trend = px.line(product_monthly, x='month', y='count', color='product_category', title="ÐžÑ‚Ð·Ñ‹Ð²Ñ‹ Ð¿Ð¾ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð°Ð¼ Ð¿Ð¾ Ð¼ÐµÑÑÑ†Ð°Ð¼",
                                           height=600)
                st.plotly_chart(fig_product_trend, use_container_width=True)
            else:
                st.write("ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ¸.")
        else:
            st.write("ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ¸.")
    else:
        st.write("ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ¸.")

    # Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑÐ¼ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð²
    st.subheader("ðŸ“‹ Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑÐ¼ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð²")
    if 'product_category' in filtered_df and not filtered_df['product_category'].isna().all():
        product_counts = filtered_df['product_category'].str.split(', ').explode().value_counts()
        if not product_counts.empty:
            if not product_filter or ('Ð’ÑÐµ' in product_filter and len(product_filter) == 1):
                product_counts_filtered = product_counts[~product_counts.index.str.contains(' - ', na=False)]
            elif 'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸' in product_filter and len(product_filter) == 1:
                product_counts_filtered = product_counts[product_counts.index.isin(['ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸'] + subcategories_filter)]
            else:
                product_counts_filtered = product_counts[~product_counts.index.str.contains(' - ', na=False)]

            if not product_counts_filtered.empty:
                fig_product = px.bar(x=product_counts_filtered.index, y=product_counts_filtered.values, title="ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð²",
                                    color=product_counts_filtered.index,
                                    color_discrete_map={
                                        'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸': '#1f77b4',
                                        'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸ - Ð’ÐµÐ´ÐµÐ½Ð¸Ðµ Ð²Ð°Ð»ÑŽÑ‚Ð½Ñ‹Ñ… ÑÑ‡ÐµÑ‚Ð¾Ð²': '#1f77b4',
                                        'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸ - Ð”ÐµÐ±ÐµÑ‚Ð¾Ð²Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹': '#1f77b4',
                                        'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸ - ÐœÐ¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð°Ð½Ðº': '#1f77b4',
                                        'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸ - ÐŸÐµÑ€ÐµÐ²Ð¾Ð´Ñ‹': '#1f77b4',
                                        'ÐŸÐ¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹ Ð¸ Ð¿Ð»Ð°Ñ‚ÐµÐ¶Ð¸ - Ð—Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹': '#1f77b4',
                                        'Ð¡Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸Ñ Ð¸ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸Ñ': '#ff7f0e',
                                        'ÐšÑ€ÐµÐ´Ð¸Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ðµ': '#2ca02c',
                                        'Ð˜Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸Ð¸': '#d62728',
                                        'Ð¡Ñ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸ Ð·Ð°Ñ‰Ð¸Ñ‚Ð°': '#9467bd',
                                        'ÐŸÑ€ÐµÐ¼Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑƒÑÐ»ÑƒÐ³Ð¸': '#8c564b',
                                        'Ð”Ñ€ÑƒÐ³Ð¾Ðµ': '#bcbd22'
                                    },
                                    height=600)
                st.plotly_chart(fig_product, use_container_width=True)
            else:
                st.write("ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹.")
        else:
            st.write("ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹.")

    # Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²
    st.subheader("ðŸ“ ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ðµ Ð¾Ñ‚Ð·Ñ‹Ð²Ñ‹")
    if not filtered_df.empty:
        group_cols_table = ['id', 'date', 'author', 'title', 'text', 'rating', 'sentiments', 'source', 'topics', 'product_category'] if all(col in filtered_df.columns for col in ['id', 'date', 'author', 'title', 'text', 'rating', 'sentiments', 'source', 'topics', 'product_category']) else ['date', 'author', 'title', 'text', 'rating', 'sentiments', 'source', 'topics', 'product_category']
        display_df = filtered_df[group_cols_table]
        st.dataframe(display_df, width=1500, height=800)
    else:
        st.write("ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹.")
else:
    st.write("ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°. Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ CSV Ð¸Ð»Ð¸ JSON Ñ Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ð¼Ð¸.")
